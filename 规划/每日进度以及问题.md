## 4.7

- [x] 修改保存方式（目前入库是post一个接口上传xlsx文件给java程序，java程序再进行数据处理后）  

1. xlsx文件保存舍去

2. 直接入库  
1） TS_B2.0.dbo.TS_Customers获取项目id  
2） 根据项目id到TS_A.dbo.TS_Keywords中获取关键词、同现词、排除词  
3）舆情通修改关键词
- 一个项目修改关键词变成两个不同的项目 
- 关于数据是否是对应项目的数据问题  
  - 查询获取到的第一条数据的关键词 包含则数据正确，不包含再次进行关键词设置

- [x] 数据处理：边抓取边处理or抓取完进行处理 

    - 规则变成python处理
        1. 标题或者url为空舍去
        
        2. url去重保留一条  数据库中有这个功能，只能抓取完进行处理
        
        3. 转发微博且内容为空的舍去
        
        4. 标题为转发微博，将内容的前20个字作为标题
        
        5. 设置数据库字段（is_original）  
            1）url中含有“weibo.com”:原创-->1、转发--->0、其他--->2  
            2）设置为2
            
        6. 地域设置
        
        7. 微博  标题、描述、转发内容
        
            只有标题为转发微博的需要进行再次详细处理
        
            | 类型 | 标题                 | 描述（摘要） | 转发内容（内容） |
            | ---- | -------------------- | ------------ | ---------------- |
            |      | content              | content      | repost_content   |
            | 原创 | content的前20个字符  | content      | content          |
            | 转发 | repost_content[0:20] | content      | repost_content   |
            | 评论 | biaoti               | biaoti       | repost_content   |
        
            
        

​    抓取完全进行处理

- [ ] 数据插入：

 - TSB_2.0
    - TS_Customers中有项目名称、行业名称
    - 根据行业名称生成一个字典
        - 行业名称:数据表名
    

- [ ] mq消息
      - 插入数据之后发送mq消息
          - messageObject.put("id",String.valueOf(list.get(i).getId()));
          - messageObject.put("industryId",String.valueOf(importIndustryDataDTO.getIndustryId()));
          - 消息队列
              - "reptile.stay.process"
              - "reptile.stay.process_2.1"




## 4.8
- 发现问题
    1. sheet表格名称错误
    2. CronTrigger设置时间错误
    3. 发布人抓取错误
-[x] 修改sheet表格名称 程序继续运行
-[x] 发布人模板修改添加re规则
    - re 去掉不想要的符号
    - pyquery（参考链接：http://cache.baiducontent.com/c?m=SvUVVUAs-pv8aCIpcCd7336Qn3fz6ldak_1lyKJvZsBOBH11wzRyWI-sFKVPvvXqdfgwoO-BpOsvyJdw7UHAFhj_5rDc_dP751dhlMsuFyvvgQnKiu2RsSxJDXGQ8-Gv&p=817dc54ad5c240f512acc7710f5680&newp=81769a47a4955fed08e2977f0c4e86231610db2151d7d7136b82c825d7331b001c3bbfb423291601d7c77d6001af4e5de9f436723d0923a3dda5c91d9fb4c57479fa712a32&s=cfcd208495d565ef&user=baidu&fm=sc&query=pyquery+contains&qid=faafa7ba00002212&p1=1）  
    `[attr*=value]` `$("p[href*='link']")` `href 属性包含"link"的p元素`
-[x] 2021-04-08 00:02:00抓取数据
    - 数据时间为 2021-04-07 23:00:00 - 2021-04-08 00:00:00 


### 计划
- 情感分析
- 二级页面抓取
- 数据过滤 布隆
- 数据处理
- mongobd sqlserver oracle




